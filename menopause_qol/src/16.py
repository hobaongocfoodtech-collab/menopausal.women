import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from lazypredict.Supervised import LazyRegressor
from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.neighbors import KNeighborsRegressor
import xgboost as xgb
import lightgbm as lgb
import warnings
import logging
import os

# --- 1. T·∫ÆT C√ÅC C·∫¢NH B√ÅO R√ÅC ---
warnings.filterwarnings('ignore')
# T·∫Øt th√¥ng b√°o spam c·ªßa LightGBM
logging.getLogger("lightgbm").setLevel(logging.ERROR)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

# --- C·∫§U H√åNH ---
FILE_PATH = r"/menopause_qol\data\processed\clean_data_final.csv"

FEATURES = ['Age', 'BMI', 'Education_Code', 'Income_Code', 'Marital_Code',
            'Job_Code', 'Info_Search_Code', 'Meno_Duration', 'Meno_Group']

# L∆∞·ªõi tham s·ªë (ƒê√£ t·ªëi ∆∞u ƒë·ªÉ ch·∫°y nhanh h∆°n)
PARAM_GRIDS = {
    'ExtraTreesRegressor': {
        'n_estimators': [100, 200],
        'max_depth': [3, 5, 7],
        'min_samples_leaf': [2, 4],
        'min_samples_split': [2, 5]
    },
    'RandomForestRegressor': {
        'n_estimators': [100, 200],
        'max_depth': [3, 5, 7],
        'min_samples_leaf': [2, 4],
        'max_features': ['sqrt', 'log2']
    },
    'GradientBoostingRegressor': {
        'n_estimators': [100],
        'learning_rate': [0.05, 0.1],
        'max_depth': [3, 4],
        'subsample': [0.8]
    },
    'XGBRegressor': {
        'n_estimators': [100],
        'learning_rate': [0.05, 0.1],
        'max_depth': [3, 5],
        'subsample': [0.8]
    },
    'LGBMRegressor': {
        'n_estimators': [100],
        'learning_rate': [0.05, 0.1],
        'max_depth': [3, 5],
        'num_leaves': [15, 31],
        'verbose': [-1]  # T·∫Øt log
    },
    'SVR': {'C': [1, 10], 'gamma': ['scale', 0.1], 'kernel': ['rbf']},
    'Ridge': {'alpha': [0.1, 1.0, 10.0]},
    'Lasso': {'alpha': [0.001, 0.01, 0.1]},
    'ElasticNet': {'alpha': [0.01, 0.1], 'l1_ratio': [0.5]},
    'KNeighborsRegressor': {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}
}

MODEL_MAP = {
    'ExtraTreesRegressor': ExtraTreesRegressor(random_state=42),
    'RandomForestRegressor': RandomForestRegressor(random_state=42),
    'GradientBoostingRegressor': GradientBoostingRegressor(random_state=42),
    'XGBRegressor': xgb.XGBRegressor(random_state=42, verbosity=0),
    'LGBMRegressor': lgb.LGBMRegressor(random_state=42, verbose=-1),
    'SVR': SVR(),
    'Ridge': Ridge(),
    'Lasso': Lasso(),
    'ElasticNet': ElasticNet(),
    'KNeighborsRegressor': KNeighborsRegressor()
}


def run_full_workflow():
    if not os.path.exists(FILE_PATH):
        print(f"‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y file {FILE_PATH}")
        return

    df = pd.read_csv(FILE_PATH)
    print(f"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu: {df.shape}")

    targets = ['PSS_Score', 'MENQOL_Score']

    for target in targets:
        print("\n" + "#" * 80)
        print(f"üöÄ B·∫ÆT ƒê·∫¶U QUY TR√åNH CHO M·ª§C TI√äU: {target}")
        print("#" * 80)

        # --- B∆Ø·ªöC 0: SPLIT DATA ---
        X = df[FEATURES]
        y = df[target]
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        print(f"[B∆∞·ªõc 0] Split Data: Train={len(X_train)}, Test={len(X_test)}")

        # --- B∆Ø·ªöC 1: LAZY PREDICT ---
        print("\n[B∆∞·ªõc 1] S√†ng l·ªçc m√¥ h√¨nh v·ªõi LazyPredict (M·∫∑c ƒë·ªãnh)...")
        reg = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric=None)
        models_lazy, predictions = reg.fit(X_train, X_test, y_train, y_test)

        # L·ªçc ra c√°c model c√≥ trong MODEL_MAP
        top_models_df = models_lazy[models_lazy.index.isin(MODEL_MAP.keys())].head(3)
        top_3_names = top_models_df.index.tolist()

        print(f"\nüèÜ Top 3 ·ª©ng c·ª≠ vi√™n s√°ng gi√° cho {target}:")
        # --- S·ª¨A L·ªñI ·ªû ƒê√ÇY: ƒê·ªïi 'Time' th√†nh 'Time Taken' ---
        cols_to_show = ['R-Squared', 'RMSE', 'Time Taken']
        # Ki·ªÉm tra xem c·ªôt n√†o t·ªìn t·∫°i th√¨ in ra
        valid_cols = [c for c in cols_to_show if c in top_models_df.columns]
        print(top_models_df[valid_cols])

        print(f"-> Ch·ªçn: {top_3_names}")

        # --- B∆Ø·ªöC 2: FINE-TUNING ---
        print("\n[B∆∞·ªõc 2] Tinh ch·ªânh tham s·ªë & Ki·ªÉm tra Overfitting (GridSearch CV)...")

        tuned_results = []

        for name in top_3_names:
            print(f"\n   >>> ƒêang t·ªëi ∆∞u h√≥a: {name}...")
            base_model = MODEL_MAP[name]
            param_grid = PARAM_GRIDS.get(name, {})

            grid = GridSearchCV(
                estimator=base_model,
                param_grid=param_grid,
                cv=5,
                scoring='r2',
                n_jobs=-1,
                verbose=0
            )

            grid.fit(X_train, y_train)

            best_model = grid.best_estimator_
            best_r2_cv = grid.best_score_
            train_r2 = best_model.score(X_train, y_train)
            gap = train_r2 - best_r2_cv

            print(f"       - Best Params: {grid.best_params_}")
            print(f"       - R2 Train: {train_r2:.4f} | R2 CV (Valid): {best_r2_cv:.4f}")
            print(f"       - Overfit Gap: {gap:.4f}")

            tuned_results.append({
                'Model Name': name,
                'Model Instance': best_model,
                'R2 CV': best_r2_cv
            })

        # --- B∆Ø·ªöC 3: FINAL EVALUATION ---
        print("\n[B∆∞·ªõc 3] So s√°nh ƒë·ªëi kh√°ng tr√™n T·∫≠p Test...")

        final_metrics = []

        for item in tuned_results:
            model = item['Model Instance']
            name = item['Model Name']

            y_pred = model.predict(X_test)

            r2 = r2_score(y_test, y_pred)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            mae = mean_absolute_error(y_test, y_pred)

            final_metrics.append({
                'M√¥ h√¨nh': name,
                'R2 Test': r2,
                'RMSE Test': rmse,
                'MAE Test': mae
            })

        final_df = pd.DataFrame(final_metrics).sort_values(by='R2 Test', ascending=False)
        print("\nüìä B·∫¢NG X·∫æP H·∫†NG CU·ªêI C√ôNG (FINAL LEADERBOARD):")
        print(final_df)

        plt.figure(figsize=(10, 5))
        sns.barplot(x='R2 Test', y='M√¥ h√¨nh', data=final_df, palette='viridis')
        plt.title(f'Hi·ªáu nƒÉng th·ª±c t·∫ø tr√™n t·∫≠p Test - M·ª•c ti√™u: {target}')
        plt.xlim(0, 1)
        plt.tight_layout()
        plt.show()

        best_final_model = final_df.iloc[0]['M√¥ h√¨nh']
        print(f"\n‚úÖ K·∫æT LU·∫¨N: M√¥ h√¨nh tri·ªÉn khai cho {target} l√†: {best_final_model}")


if __name__ == "__main__":
    run_full_workflow()